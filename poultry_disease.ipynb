{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = 'Dataset.zip'  # Path to your zip file\n",
    "unzip_dir = 'dataset'  # Directory where the files will be extracted\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_dir)\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: The zip file might have unusual formatting or features.\")\n",
    "    print(\"Trying to extract using 'shutil' module as an alternative...\")\n",
    "    import shutil\n",
    "    shutil.unpack_archive(zip_file, unzip_dir, 'zip')  # Use shutil to extract\n",
    "    print(\"Extraction successful using shutil.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "label\n",
      "healthy      6395\n",
      "unhealthy    5299\n",
      "Name: count, dtype: int64\n",
      "Test Data:\n",
      "image_path    2924\n",
      "label         2924\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "# Adjusting paths based on your new directory structure\n",
    "unzip_dir = 'dataset'  # This is the base folder where 'Dataset' is located\n",
    "healthy_folder = os.path.join(unzip_dir, 'Dataset/Healthy')  # Path to 'Healthy' folder\n",
    "unhealthy_folder = os.path.join(unzip_dir, 'Dataset/Unhealthy')  # Path to 'Unhealthy' folder\n",
    "\n",
    "# Check if the folders exist (just for safety)\n",
    "if not os.path.exists(healthy_folder):\n",
    "    print(f\"Healthy folder does not exist: {healthy_folder}\")\n",
    "if not os.path.exists(unhealthy_folder):\n",
    "    print(f\"Unhealthy folder does not exist: {unhealthy_folder}\")\n",
    "\n",
    "# Iterate through both folders and create labels\n",
    "for label, folder in [('healthy', healthy_folder), ('unhealthy', unhealthy_folder)]:\n",
    "    if os.path.exists(folder):  # Proceed only if the folder exists\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith(('.png', '.jpg', '.jpeg', 'JPG')):  # Check for image files\n",
    "                image_path = os.path.join(folder, filename)\n",
    "                data.append([image_path, label])\n",
    "\n",
    "# Step 3: Load into a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
    "\n",
    "# Step 4: Split the dataset into train and test sets (80% train, 20% test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optionally, you can save these datasets to CSVs or use them in further processing\n",
    "train_df.to_csv('train_dataset.csv', index=False)\n",
    "test_df.to_csv('test_dataset.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the training and test data\n",
    "print(\"Training Data:\")\n",
    "print(train_df['label'].value_counts())\n",
    "\n",
    "print(\"Test Data:\")\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# Step 1: Load the train and test datasets\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Epoch [1/10], Loss: 0.2089, Accuracy: 91.26%\n",
      "Epoch [2/10], Loss: 0.0377, Accuracy: 98.84%\n",
      "Epoch [3/10], Loss: 0.0193, Accuracy: 99.44%\n",
      "Epoch [4/10], Loss: 0.0138, Accuracy: 99.52%\n",
      "Epoch [5/10], Loss: 0.0106, Accuracy: 99.72%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     83\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     87\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/function.py:264\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Custom Dataset Class to Load Images\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = 1 if self.dataframe.iloc[idx, 1] == 'healthy' else 0\n",
    "        image = datasets.folder.default_loader(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Step 3: Define transformations (for training and testing)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # EfficientNet expects 224x224 input size\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_dataset = CustomImageDataset(dataframe=train_df, transform=train_transforms)\n",
    "test_dataset = CustomImageDataset(dataframe=test_df, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Load EfficientNet Model (Pre-trained)\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# Modify the final layer for binary classification (2 classes: healthy, unhealthy)\n",
    "model._fc = nn.Linear(in_features=model._fc.in_features, out_features=2)\n",
    "\n",
    "# Step 6: Set device for training (CUDA if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Step 7: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Step 8: Train the Model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Step 9: Evaluate the Model on Test Set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the model's state_dict (weights)\n",
    "torch.save(model.state_dict(), 'efficientnet_model2.pth')\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model architecture\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model._fc = nn.Linear(in_features=model._fc.in_features, out_features=2)  # Modify for binary classification\n",
    "\n",
    "# Load the saved state_dict\n",
    "model.load_state_dict(torch.load('efficientnet_model.pth'))\n",
    "model = model.to(device)  # Make sure to move the model to the correct device (CPU or GPU)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9959\n",
      "Precision: 0.9950\n",
      "Recall: 0.9975\n",
      "F1 Score: 0.9962\n",
      "ROC AUC: 0.9996\n",
      "PR AUC: 0.9996\n",
      "Confusion Matrix:\n",
      "[[1320    8]\n",
      " [   4 1592]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1328\n",
      "           1       0.99      1.00      1.00      1596\n",
      "\n",
      "    accuracy                           1.00      2924\n",
      "   macro avg       1.00      1.00      1.00      2924\n",
      "weighted avg       1.00      1.00      1.00      2924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 10: Compute all necessary metrics (accuracy, precision, recall, F1 score, ROC AUC, PR AUC, confusion matrix)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []  # To store predicted probabilities for ROC AUC and PR AUC\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Store the predicted probabilities for ROC AUC and PR AUC (softmax output)\n",
    "        prob = torch.softmax(outputs, dim=1)[:, 1]  # Probabilities for the 'healthy' class\n",
    "        y_prob.extend(prob.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays for easier handling with sklearn\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
    "\n",
    "# Precision, Recall, F1 Score\n",
    "precision = precision_score(y_true, y_pred, average='binary')\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n",
    "f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "# ROC AUC (Area Under the ROC Curve)\n",
    "roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# PR AUC (Area Under the Precision-Recall Curve)\n",
    "pr_auc = average_precision_score(y_true, y_prob)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'ROC AUC: {roc_auc:.4f}')\n",
    "print(f'PR AUC: {pr_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/shafayat/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:25<00:00, 4.04MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3288, Accuracy: 86.18%\n",
      "Epoch [2/10], Loss: 0.1428, Accuracy: 95.70%\n",
      "Epoch [3/10], Loss: 0.0931, Accuracy: 97.44%\n",
      "Epoch [4/10], Loss: 0.0649, Accuracy: 97.33%\n",
      "Epoch [5/10], Loss: 0.0533, Accuracy: 97.79%\n",
      "Epoch [6/10], Loss: 0.0540, Accuracy: 97.56%\n",
      "Epoch [7/10], Loss: 0.0418, Accuracy: 98.95%\n",
      "Epoch [8/10], Loss: 0.0479, Accuracy: 97.79%\n",
      "Epoch [9/10], Loss: 0.0455, Accuracy: 98.14%\n",
      "Epoch [10/10], Loss: 0.0328, Accuracy: 98.61%\n",
      "Test Accuracy: 97.69%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load the train and test datasets\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "# Step 2: Custom Dataset Class to Load Images\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]\n",
    "        label = 1 if self.dataframe.iloc[idx, 1] == 'healthy' else 0\n",
    "        image = datasets.folder.default_loader(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Step 3: Define transformations (for training and testing)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet expects 224x224 input size\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_dataset = CustomImageDataset(dataframe=train_df, transform=train_transforms)\n",
    "test_dataset = CustomImageDataset(dataframe=test_df, transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Load ResNet Model (Pre-trained)\n",
    "model = models.resnet50(pretrained=True)  # Use ResNet-18, or you can try resnet34, resnet50, etc.\n",
    "\n",
    "# Modify the final layer for binary classification (2 classes: healthy, unhealthy)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # Output 2 classes\n",
    "\n",
    "# Step 6: Set device for training (CUDA if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Step 7: Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Step 8: Train the Model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Step 9: Evaluate the Model on Test Set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9907\n",
      "Precision: 0.9880\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9939\n",
      "ROC AUC: 0.9999\n",
      "PR AUC: 1.0000\n",
      "Confusion Matrix:\n",
      "[[196   8]\n",
      " [  0 657]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       204\n",
      "           1       0.99      1.00      0.99       657\n",
      "\n",
      "    accuracy                           0.99       861\n",
      "   macro avg       0.99      0.98      0.99       861\n",
      "weighted avg       0.99      0.99      0.99       861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Step 10: Compute all necessary metrics (accuracy, precision, recall, F1 score, ROC AUC, PR AUC, confusion matrix)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_prob = []  # To store predicted probabilities for ROC AUC and PR AUC\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Store the predicted probabilities for ROC AUC and PR AUC (softmax output)\n",
    "        prob = torch.softmax(outputs, dim=1)[:, 1]  # Probabilities for the 'healthy' class\n",
    "        y_prob.extend(prob.cpu().numpy())\n",
    "\n",
    "# Convert to numpy arrays for easier handling with sklearn\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
    "\n",
    "# Precision, Recall, F1 Score\n",
    "precision = precision_score(y_true, y_pred, average='binary')\n",
    "recall = recall_score(y_true, y_pred, average='binary')\n",
    "f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Classification Report\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "# ROC AUC (Area Under the ROC Curve)\n",
    "roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# PR AUC (Area Under the Precision-Recall Curve)\n",
    "pr_auc = average_precision_score(y_true, y_prob)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'ROC AUC: {roc_auc:.4f}')\n",
    "print(f'PR AUC: {pr_auc:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), 'resnet50_model.pth')\n",
    "print(\"model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "# Modify the final layer for binary classification (2 classes: healthy, unhealthy)\n",
    "model.fc = torch.nn.Linear(in_features=model.fc.in_features, out_features=2)\n",
    "\n",
    "# Step 2: Load the saved state_dict (weights), allowing for mismatch in final layer\n",
    "model.load_state_dict(torch.load('resnet50_model.pth'), strict=False)\n",
    "print(\"loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path    861\n",
       "label         861\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[9]['image_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0, Probability: 0.9989749193191528\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "test_transformss = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # Load the image from the file path\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Apply the necessary transformations\n",
    "    image = test_transforms(image).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Move the image tensor to the device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image = image.to(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():  # No need to calculate gradients during inference\n",
    "        outputs = model(image)\n",
    "        softmax = torch.nn.Softmax(dim=1)  # Apply Softmax to get probabilities\n",
    "        probabilities = softmax(outputs)\n",
    "\n",
    "        # Get the predicted class\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "        prediction_prob = probabilities[0][predicted_class].item()\n",
    "\n",
    "    # Output the prediction class and its probability\n",
    "    return predicted_class, prediction_prob\n",
    "\n",
    "# Example usage:\n",
    "image_path = test_df.iloc[9]['image_path']  # Specify your image path here\n",
    "predicted_class, prediction_prob = predict_image(image_path)\n",
    "print(f\"Predicted class: {predicted_class}, Probability: {prediction_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_9940.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_1511(0).JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_5535.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_1292(0).JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_5471.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_4557.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_5468.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_8006.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_2354.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_0883(0).JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_3476.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_5695.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_8483.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_2245(0).JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_8059.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_6563.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_3541.jpeg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_2547.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dataset/Dataset/Unhealthy/IMG_5142.JPG</td>\n",
       "      <td>unhealthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dataset/Dataset/Healthy/IMG_5915.JPG</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_path      label\n",
       "0      dataset/Dataset/Healthy/IMG_9940.JPG    healthy\n",
       "1   dataset/Dataset/Healthy/IMG_1511(0).JPG    healthy\n",
       "2    dataset/Dataset/Unhealthy/IMG_5535.JPG  unhealthy\n",
       "3   dataset/Dataset/Healthy/IMG_1292(0).JPG    healthy\n",
       "4    dataset/Dataset/Unhealthy/IMG_5471.JPG  unhealthy\n",
       "5     dataset/Dataset/Healthy/IMG_4557.jpeg    healthy\n",
       "6      dataset/Dataset/Healthy/IMG_5468.JPG    healthy\n",
       "7      dataset/Dataset/Healthy/IMG_8006.JPG    healthy\n",
       "8    dataset/Dataset/Unhealthy/IMG_2354.JPG  unhealthy\n",
       "9   dataset/Dataset/Healthy/IMG_0883(0).JPG    healthy\n",
       "10   dataset/Dataset/Unhealthy/IMG_3476.JPG  unhealthy\n",
       "11     dataset/Dataset/Healthy/IMG_5695.JPG    healthy\n",
       "12     dataset/Dataset/Healthy/IMG_8483.JPG    healthy\n",
       "13  dataset/Dataset/Healthy/IMG_2245(0).JPG    healthy\n",
       "14     dataset/Dataset/Healthy/IMG_8059.JPG    healthy\n",
       "15   dataset/Dataset/Unhealthy/IMG_6563.JPG  unhealthy\n",
       "16    dataset/Dataset/Healthy/IMG_3541.jpeg    healthy\n",
       "17   dataset/Dataset/Unhealthy/IMG_2547.JPG  unhealthy\n",
       "18   dataset/Dataset/Unhealthy/IMG_5142.JPG  unhealthy\n",
       "19     dataset/Dataset/Healthy/IMG_5915.JPG    healthy"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m sample_size_per_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_label \u001b[38;5;129;01min\u001b[39;00m classes:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Filter the dataset for the current class\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     class_df \u001b[38;5;241m=\u001b[39m test_df[\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m class_label]\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Randomly sample 10 rows from the current class\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     sampled_class_df \u001b[38;5;241m=\u001b[39m class_df\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39msample_size_per_class, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# Step 1: Load the test dataset\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "# Step 2: Create a folder to save the test samples\n",
    "sample_folder = 'test_samples'\n",
    "os.makedirs(sample_folder, exist_ok=True)\n",
    "\n",
    "# Assuming the dataset has a 'class' column that indicates the class (e.g., 0, 1, etc.)\n",
    "# If your dataset has different class labels, replace 'class' with the correct column name.\n",
    "\n",
    "# Step 3: Split the dataset into two folders based on class\n",
    "classes = test_df['label'].unique()  # Get unique class labels\n",
    "\n",
    "# Create subfolders for each class inside 'test_samples'\n",
    "for class_label in classes:\n",
    "    class_folder = os.path.join(sample_folder, str(class_label))\n",
    "    os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "# Step 4: Select 10 random samples from each class\n",
    "sample_size_per_class = 10\n",
    "\n",
    "for class_label in classes:\n",
    "    # Filter the dataset for the current class\n",
    "    class_df = test_df[test_df['label'] == class_label]\n",
    "    \n",
    "    # Randomly sample 10 rows from the current class\n",
    "    sampled_class_df = class_df.sample(n=sample_size_per_class, random_state=42)\n",
    "\n",
    "    # Step 5: Copy the corresponding images to the class-specific folder\n",
    "    for index, row in sampled_class_df.iterrows():\n",
    "        image_path = row['image_path']  # Adjust the column name if needed\n",
    "        image_name = os.path.basename(image_path)  # Get the image file name\n",
    "\n",
    "        # Check if the image file exists before copying\n",
    "        if os.path.exists(image_path):\n",
    "            destination_path = os.path.join(sample_folder, str(class_label), image_name)\n",
    "            shutil.copy(image_path, destination_path)\n",
    "            print(f\"Copied {image_name} to {destination_path}\")\n",
    "        else:\n",
    "            print(f\"Image {image_path} not found!\")\n",
    "\n",
    "print(f\"Successfully saved {sample_size_per_class} samples from each class to {sample_folder}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
